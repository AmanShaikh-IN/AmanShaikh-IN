# Hi, I'm Aman Razak Shaikh

I'm an undergraduate student in **Artificial Intelligence and Data Science** with a strong focus on  
**Generative AI, Large Language Models (LLMs), and Deep Learning systems**.

My work sits at the intersection of **modern AI research and system-level engineering** — building, fine-tuning, and deploying AI models while being deeply aware of performance, scalability, and real-world constraints.

---

## Primary Focus Areas
- Generative AI and Large Language Models (LLMs)
- Retrieval-Augmented Generation (RAG) systems
- Parameter-efficient fine-tuning (LoRA, QLoRA)
- Multimodal deep learning (audio–visual systems)
- Deep learning with PyTorch and CUDA
- Agentic and multi-agent AI systems

---

## Experience Highlights

### Research Intern — Centre for Development of Advanced Computing (C-DAC)
*Worked with PARAM Siddhi Supercomputer*

- Designed and developed **multimodal synchronization and segmentation pipelines** for automated data curation, targeting downstream generative AI tasks such as voice cloning.
- Implemented and evaluated **dual-stream CNN-based architectures** for joint audio–video processing, speaker identification, and temporal alignment.
- Applied **embedding-based similarity search** and vector databases to store and retrieve speaker representations efficiently.
- Prototyped and validated components using **state-of-the-art multimodal models (Qwen-2.5-Omni)** as part of a large-scale research initiative.
- Collaborated with senior researchers on documentation and experimentation for a research paper currently in preparation.
- Gained hands-on exposure to **large-scale compute environments** and performance-aware deep learning workflows on national HPC infrastructure.

---

### Computer Vision & ML Lead — Team Raptors (South Asia Pacific RoboCon)
- Led development of **computer vision–based autonomous navigation systems** using YOLOv8, OpenCV, and Python.
- Designed large-scale **data preparation, annotation, and augmentation pipelines** to improve robustness under competition constraints.
- Trained and optimized deep learning models using **CUDA-accelerated pipelines**.
- Integrated perception outputs with **C++-based kinematics, control logic, and sensor fusion**, supporting both autonomous and manual robot control.
- Contributed to qualification for **national-level RoboCon finals**.

---

## Selected Projects

### QLoRA-Based Fine-Tuning with Gemma-7B
- Fine-tuned Google’s Gemma-7B using **QLoRA with 4-bit quantization**, reducing memory usage by ~75%.
- Achieved significant training loss reduction using LoRA rank-16 adapters, gradient checkpointing, and mixed precision.
- Stack: PyTorch, Transformers, PEFT, TRL, BitsAndBytes

### RAG-Based Research Paper Assistant (AWS Bedrock)
- Built a **history-aware RAG system** for intelligent querying of academic papers.
- Implemented contextual query reformulation to improve follow-up retrieval accuracy.
- Stack: AWS Bedrock, FAISS, LangChain, Streamlit, Amazon Titan

### Multi-Tool Agent Systems with LangChain & LangGraph
- Developed **stateful agentic systems** combining traditional LangChain agents and LangGraph-based ReAct workflows.
- Implemented hybrid retrieval using vector databases and tool-based reasoning.
- Stack: LangChain, LangGraph, AstraDB, Hugging Face, Groq API

---

## Technical Skill Set

### Programming Languages
- Python
- C / C++
- Bash

### Generative AI & LLMs
- Transformers
- LangChain, LangGraph, CrewAI
- Agentic and multi-agent systems
- RAG pipelines and vector databases
- Prompt engineering and context management
- LoRA, QLoRA, PEFT techniques

### Machine Learning & Deep Learning
- PyTorch
- CUDA-enabled training
- CNNs and multimodal architectures
- Model optimization and evaluation
- Scikit-learn

### Data & Systems
- FAISS and vector search
- PostgreSQL
- NumPy, Pandas
- Dataset curation and annotation workflows
- Linux-based development environments

### Cloud & Deployment
- AWS (EC2, Bedrock)
- Docker
- Streamlit
- FastAPI
- Git & GitHub

---

## Systems & Embedded Background
I also have substantial experience in **embedded systems, robotics, and low-level programming**, including real-time perception, control logic, and sensor fusion in competition-grade robots.  
This background strongly influences how I design AI systems — particularly around **latency, memory efficiency, scalability, and deployment feasibility** — and complements my current focus on large-scale AI and LLM-based systems.

---

## Research & Technical Interests
- Applied Generative AI
- Multimodal AI systems
- LLM behavior, evaluation, and interpretability
- ML systems and infrastructure
- Performance-aware deep learning

---

## Contact
- GitHub: https://github.com/AmanShaikh-IN
- LinkedIn: (add when ready)
